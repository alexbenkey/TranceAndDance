# Both backend and frontend services are configured to send logs to Logstash using the GELF logging driver.
# Logs are sent to the udp://logstash:5044 endpoint.

# Configured to use a GELF input plugin to receive logs.
# Sends logs to Elasticsearch for indexing, under an index named logs-YYYY.MM.dd.

input {
  beats {
    port => 5044
    tags => ["app-logs"]
  }
}

filter {
  if "app-logs" in [tags] and [log][file][path] =~ "django" {
    # Parse the JSON message field
    json {
      source => "message"
      target => "parsed_message"
    }

    # Extract Django app name from parsed message
    mutate {
      add_field => { "django_app" => "%{[parsed_message][name]}" }
    }

    # Normalize app names by replacing dots with underscores (Elasticsearch doesn't allow dots in field names)
    mutate {
      gsub => ["django_app", "\.", "_"]
    }

    # Set index dynamically based on the Django app
    mutate {
      add_field => { "[@metadata][index]" => "backend-%{django_app}" }
    }
  }

      # Categorize logs based on event.original.name
    if [parsed_message][name] {
      mutate {
        add_field => { "log_category" => "%{[parsed_message][name]}" }
      }
    } else {
      mutate {
        add_field => { "log_category" => "unknown" }
      }
    }

  # For Nginx logs
  if "app-logs" in [tags] and [log][file][path] =~ "nginx" {
    grok {
      match => {
        "message" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME} \[%{LOGLEVEL:log_level}\] %{POSINT:pid}#%{NUMBER:thread_id}: %{GREEDYDATA:log_message}"
      }
    }
    mutate { 
      add_field => { "[@metadata][index]" => "frontend" }
    }
  }
}

output {
  stdout {
    codec => rubydebug  # Helps debug Logstash processing
  }

  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][index]}-logs-%{+YYYY.MM.dd}"
  }
}



#This one works for front/back
# input {
#   beats {
#     port => 5044
#     tags => ["app-logs"]
#   }
# }


# filter {
#   # For JSON logs (Django/Backend)
#   if [input][type] == "filestream" and [log][file][path] =~ "django" {
#     mutate { 
#       add_field => { "[@metadata][index]" => "backend" }
#     }
#   }
  
#   # For Nginx logs
#   if [input][type] == "filestream" and [log][file][path] =~ "nginx" {
#     grok {
#       match => {
#         "message" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME} \[%{LOGLEVEL:log_level}\] %{POSINT:pid}#%{NUMBER:thread_id}: %{GREEDYDATA:log_message}"
#       }
#     }
#     mutate { 
#       add_field => { "[@metadata][index]" => "frontend" }
#     }
#   }
# }

# output {
#   stdout {
#     codec => rubydebug  # Helps debug Logstash processing
#   }

#   elasticsearch {
#     hosts => ["http://elasticsearch:9200"]
#     index => "%{[@metadata][index]}-logs-%{+YYYY.MM.dd}" 
#     #index => "debug-logs-%{+YYYY.MM.dd}"

#   }
# }


#proper one
# input {
#   beats {
#     port => 5044
#     tags => ["app-logs"]
#   }
# }

# filter {
#   if "app-logs" in [tags] {
#     mutate { 
#       add_field => { "[@metadata][index]" => "backend" }
#     }
#   }
# }

# # filter {
# #   if "app-logs" in [tags] {
# #     if [fields][name] =~ /^django.*/ {
# #       mutate { add_field => { "[@metadata][index]" => "backend" } }
# #     } else {
# #       mutate { add_field => { "[@metadata][index]" => "backend" } }  # Default index
# #     }
# #   }
# # }

# output {
#   stdout {
#     codec => rubydebug  # Helps debug Logstash processing
#   }

#   elasticsearch {
#     hosts => ["http://elasticsearch:9200"]
#     index => "%{[@metadata][index]}-logs-%{+YYYY.MM.dd}" 
#     #index => "debug-logs-%{+YYYY.MM.dd}"

#   }
# }

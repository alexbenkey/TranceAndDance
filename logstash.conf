# Both backend and frontend services are configured to send logs to Logstash using the GELF logging driver.
# Logs are sent to the udp://logstash:5044 endpoint.

# Configured to use a GELF input plugin to receive logs.
# Sends logs to Elasticsearch for indexing, under an index named logs-YYYY.MM.dd.

input {
  tcp {
    port => 5044
    codec => json
    tags => ["app-logs"]
  }
}

filter {
  if "app-logs" in [tags] {
    if [logger_name] =~ "django.*" {
      mutate { add_field => { "[@metadata][index]" => "backend" } }
    }
    else {
      if [type] == "frontend" {
        mutate { add_field => { "[@metadata][index]" => "frontend" } }
      }
      else {
        mutate { add_field => { "[@metadata][index]" => "db" } }
      }
    }
  }
  # if "app-logs" in [tags] {
  #   if [logger_name] =~ "django.*" {
  #     mutate { add_field => { "[@metadata][index]" => "backend" } }
  #   }
  #   else if [type] == "frontend" {
  #     mutate { add_field => { "[@metadata][index]" => "frontend" } }
  #   }
  #   else {
  #     mutate { add_field => { "[@metadata][index]" => "db" } }
  #   }
  # }
}

output {
  stdout {
    codec => rubydebug #will print the entire event structure in a human-readable format
  }
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index]}-logs-%{+YYYY.MM.dd}"
  }
}

# input {
#   tcp {
#     port => 5044
#     codec => json
#   }
# }

# output {
#   elasticsearch {
#     hosts => ["elasticsearch:9200"]
#     index => "logs-%{+YYYY.MM.dd}"
#   }
# }
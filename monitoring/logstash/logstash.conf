# Both backend and frontend services are configured to send logs to Logstash using the GELF logging driver.
# Logs are sent to the udp://logstash:5044 endpoint.

# Configured to use a GELF input plugin to receive logs.
# Sends logs to Elasticsearch for indexing, under an index named logs-YYYY.MM.dd.

input {
  beats {
    port => 5044
    tags => ["app-logs"]
  }
}

filter {
  if "app-logs" in [tags] and [log][file][path] =~ "django" {
    # Parse the JSON message field
    json {
      source => "message"
      target => "parsed_message"
    }

    # Extract Django app name from parsed message
    mutate {
      add_field => { "django_app" => "%{[parsed_message][name]}" }
    }

    # Normalize app names by replacing dots with underscores (Elasticsearch doesn't allow dots in field names)
    mutate {
      gsub => ["django_app", "\.", "_"]
    }

    # Set index dynamically based on the Django app
    mutate {
      add_field => { "[@metadata][index]" => "backend-%{django_app}" }
    }
  }

      # Categorize logs based on event.original.name
    if [parsed_message][name] {
      mutate {
        add_field => { "log_category" => "%{[parsed_message][name]}" }
      }
    } else {
      mutate {
        add_field => { "log_category" => "unknown" }
      }
    }

# For Nginx logs
if "app-logs" in [tags] and [log][file][path] =~ "nginx" {

  #  Nginx error logs
  if [message] =~ "^\d{4}/\d{2}/\d{2}" {
    grok {
      match => {
        "message" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME} \[%{LOGLEVEL:log_level}\] %{POSINT:pid}#%{NUMBER:thread_id}: %{GREEDYDATA:log_message}"
      }
    }
    mutate { 
      add_field => { "[@metadata][index]" => "frontend-nginx_error" }
    }
  } 

  # nginx access logs
  else {
    grok {
      match => {
        "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status} %{NUMBER:bytes} \"%{DATA:referrer}\" \"%{DATA:user_agent}\""
      }
    }
    mutate { 
      add_field => { "[@metadata][index]" => "frontend-nginx_access" }
    }
  }
}

  # # For Nginx logs
  # if "app-logs" in [tags] and [log][file][path] =~ "nginx" {
  #   grok {
  #     match => {
  #       "message" => "%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME} \[%{LOGLEVEL:log_level}\] %{POSINT:pid}#%{NUMBER:thread_id}: %{GREEDYDATA:log_message}"
  #     }
  #   }
  #   mutate { 
  #     add_field => { "[@metadata][index]" => "frontend" }
  #   }
  # }
}

output {
  stdout {
    codec => rubydebug  # Helps debug Logstash processing
  }

  elasticsearch {
    hosts => "${ELASTICSEARCH_HOST_PORT}"
    user => "${ELASTIC_USERNAME}"
    password => "${ELASTIC_PASSWORD}"
    ssl => true
    ssl_certificate_verification => true
    cacert => "/certs/ca.crt"
    index => "%{[@metadata][index]}-logs-%{+YYYY.MM.dd}"
  }
}



